{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bpkJZ9WHtQV",
        "outputId": "0d96af68-6139-4276-bd83-e318ff8f61bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.10.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "# Mount Google Drive to access your dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install any missing dependencies\n",
        "!pip install albumentations opencv-python-headless numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# Path to the shortcut folder in your Google Drive\n",
        "BASE_DIR = \"/content/drive/My Drive/FYP_work/DecayDataSrc\"\n",
        "\n",
        "# Test if the shortcut folder is accessible\n",
        "import os\n",
        "\n",
        "print(\"DecayDataSrc directory exists:\", os.path.exists(BASE_DIR))\n",
        "print(\"Contents of DecayDataSrc:\", os.listdir(BASE_DIR) if os.path.exists(BASE_DIR) else \"Not found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az9Ep5QmHwIS",
        "outputId": "33b5d46e-aa2a-4038-f7a7-b6c61f32481b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "DecayDataSrc directory exists: True\n",
            "Contents of DecayDataSrc: ['src', 'Teeth_Dataset', 'Decay_Dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def create_directory(path_segments):\n",
        "    \"\"\"Creates a directory if it does not exist.\"\"\"\n",
        "    path = os.path.join(*path_segments)\n",
        "    # Adding a check to see if path exists and if it's writable\n",
        "    if not os.path.exists(path):\n",
        "        try:\n",
        "            os.makedirs(path, exist_ok=True)\n",
        "        except OSError as e:\n",
        "            if e.errno == 30:  # Read-only file system error\n",
        "                print(f\"Error: Cannot create directory '{path}'. File system is read-only.\")\n",
        "                # You might want to handle this error differently, e.g., by changing the path or using a different storage location.\n",
        "            else:\n",
        "                raise  # Re-raise other errors\n",
        "    # If path exists and is a directory, no need to create it\n",
        "    elif os.path.isdir(path):\n",
        "        print(f\"Directory '{path}' already exists. Skipping creation.\")\n",
        "    else:\n",
        "        print(f\"Error: '{path}' exists but is not a directory.\")\n",
        "    return path\n",
        "\n",
        "\n",
        "def interpolate_image(image, target_size):\n",
        "    \"\"\"Interpolates an image to the target size.\"\"\"\n",
        "    # ... (Your interpolation logic using cv2 or other libraries) ...\n",
        "    # Example using cv2.resize:\n",
        "    return cv2.resize(image, target_size)\n",
        "\n",
        "BASE_DIR = \"/content/drive/My Drive/FYP_work/DecayDataSrc/Decay_Dataset\"\n",
        "\n",
        "train_images_dir = f\"{BASE_DIR}/Train_Data/Images\"\n",
        "train_masks_dir = f\"{BASE_DIR}/Train_Data/Masks\"\n",
        "test_images_dir = f\"{BASE_DIR}/Test_Data/Images\"\n",
        "test_masks_dir = f\"{BASE_DIR}/Test_Data/Masks\"\n",
        "\n",
        "# Output directories\n",
        "augmented_images_dir = create_directory([BASE_DIR, \"augmented/Images\"])\n",
        "augmented_masks_dir = create_directory([BASE_DIR, \"augmented/Masks\"])\n",
        "compressed_dir = create_directory([BASE_DIR, \"compressed\"])"
      ],
      "metadata": {
        "id": "5lbKrNBtHxvy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check existence of directories\n",
        "print(\"Train images directory exists:\", os.path.exists(train_images_dir))\n",
        "print(\"Train masks directory exists:\", os.path.exists(train_masks_dir))\n",
        "\n",
        "# List files\n",
        "if os.path.exists(train_images_dir):\n",
        "    print(\"Train Images:\", os.listdir(train_images_dir)[:5])  # Show first 5 images\n",
        "if os.path.exists(train_masks_dir):\n",
        "    print(\"Train Masks:\", os.listdir(train_masks_dir)[:5])  # Show first 5 masks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usimbHpkIPXr",
        "outputId": "56b3e43c-c9a2-45cb-b8cd-adc493c3016a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images directory exists: True\n",
            "Train masks directory exists: True\n",
            "Train Images: ['556.png', '96.png', '524.png', '2.png', '11.png']\n",
            "Train Masks: ['510.png', '96.png', '576.png', '532.png', '50.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train images directory path: {train_images_dir}\")\n",
        "print(\"Directory exists:\", os.path.exists(train_images_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HGkeZb9ImFu",
        "outputId": "763de2e4-a02a-4132-e131-a8f798f6a81e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images directory path: /content/drive/My Drive/FYP_work/DecayDataSrc/Decay_Dataset/Train_Data/Images\n",
            "Directory exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_size = 224\n",
        "target_shape = (input_image_size, input_image_size)\n",
        "# Augmentation transformations\n",
        "transform_crop = A.Compose([A.RandomCrop(width=input_image_size, height=input_image_size, p=1)])\n",
        "transform_rotate90 = A.Compose([A.RandomRotate90(p=1)])\n",
        "transform_flip = A.Compose([A.HorizontalFlip(p=1)])\n",
        "transform_brightness = A.Compose([A.RandomBrightnessContrast(p=1)])\n",
        "transform_all = A.Compose([\n",
        "    A.RandomCrop(width=input_image_size, height=input_image_size, p=1),\n",
        "    A.HorizontalFlip(p=1),\n",
        "    A.RandomRotate90(p=1),\n",
        "    A.RandomBrightnessContrast(p=1)\n",
        "])"
      ],
      "metadata": {
        "id": "laWBdpFwIq3t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augment training data\n",
        "for file_name in os.listdir(train_images_dir):\n",
        "    try:\n",
        "        # Load image and mask\n",
        "        image = cv2.imread(f\"{train_images_dir}/{file_name}\", cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(f\"{train_masks_dir}/{file_name}\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Normalize mask values\n",
        "        mask[mask == 255] = 1\n",
        "\n",
        "        # Save original data\n",
        "        cv2.imwrite(f\"{augmented_images_dir}/00_{file_name}\", image)\n",
        "        #cv2.imwrite(f\"{augmented_masks_dir}/00_{file_name}\", mask)\n",
        "\n",
        "        # Apply transformations and save\n",
        "        transformed = transform_crop(image=image, mask=mask)\n",
        "        cv2.imwrite(f\"{augmented_images_dir}/01_{file_name}\", transformed[\"image\"])\n",
        "        #cv2.imwrite(f\"{augmented_masks_dir}/01_{file_name}\", transformed[\"mask\"])\n",
        "\n",
        "        transformed = transform_rotate90(image=image, mask=mask)\n",
        "        cv2.imwrite(f\"{augmented_images_dir}/02_{file_name}\", transformed[\"image\"])\n",
        "        #cv2.imwrite(f\"{augmented_masks_dir}/02_{file_name}\", transformed[\"mask\"])\n",
        "\n",
        "        transformed = transform_flip(image=image, mask=mask)\n",
        "        cv2.imwrite(f\"{augmented_images_dir}/03_{file_name}\", transformed[\"image\"])\n",
        "        #cv2.imwrite(f\"{augmented_masks_dir}/03_{file_name}\", transformed[\"mask\"])\n",
        "\n",
        "        transformed = transform_all(image=image, mask=mask)\n",
        "        cv2.imwrite(f\"{augmented_images_dir}/04_{file_name}\", transformed[\"image\"])\n",
        "        #cv2.imwrite(f\"{augmented_masks_dir}/04_{file_name}\", transformed[\"mask\"])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pZ1bC59ItY7",
        "outputId": "f06df4dc-26d7-4794-ee91-c4fb197bf271"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing 41.png: 'NoneType' object does not support item assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "\n",
        "# Define transform_noise\n",
        "transform_noise = A.Compose([\n",
        "    A.RandomBrightnessContrast(p=1, always_apply=True)\n",
        "])\n"
      ],
      "metadata": {
        "id": "wMxJnwDxfESV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in os.listdir(train_images_dir):\n",
        "    try:\n",
        "        # Load image and mask\n",
        "        image = cv2.imread(f\"{train_images_dir}/{file_name}\", cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(f\"{train_masks_dir}/{file_name}\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None or mask is None:\n",
        "            print(f\"Missing file: {file_name}\")\n",
        "            continue\n",
        "\n",
        "        # Normalize the mask: Convert white (255) to foreground (1), keep background as 0\n",
        "        mask[mask == 255] = 1\n",
        "\n",
        "        # Save the original mask\n",
        "        cv2.imwrite(f\"{augmented_masks_dir}/00_{file_name}\", (mask * 255).astype(\"uint8\"))\n",
        "\n",
        "        # Apply augmentations\n",
        "        transformed = transform_crop(image=image, mask=mask)\n",
        "        augmented_mask = transformed[\"mask\"]\n",
        "        cv2.imwrite(f\"{augmented_masks_dir}/01_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
        "\n",
        "        transformed = transform_rotate90(image=image, mask=mask)\n",
        "        augmented_mask = transformed[\"mask\"]\n",
        "        cv2.imwrite(f\"{augmented_masks_dir}/02_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
        "\n",
        "        transformed = transform_noise(image=image, mask=mask)\n",
        "        augmented_mask = transformed[\"mask\"]\n",
        "        cv2.imwrite(f\"{augmented_masks_dir}/03_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
        "\n",
        "        transformed = transform_all(image=image, mask=mask)\n",
        "        augmented_mask = transformed[\"mask\"]\n",
        "        cv2.imwrite(f\"{augmented_masks_dir}/04_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnqoHuFWelMO",
        "outputId": "cf032476-efd5-4e14-82a1-8c9fce40525c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing file: 41.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_dir = f\"{BASE_DIR}/compressed\"\n",
        "os.makedirs(compressed_dir, exist_ok=True)\n",
        "\n",
        "# Save data in .npz format\n",
        "for file_name in os.listdir(augmented_images_dir):\n",
        "    try:\n",
        "        # Load augmented image and mask\n",
        "        image = cv2.imread(f\"{augmented_images_dir}/{file_name}\", cv2.IMREAD_GRAYSCALE).astype(\"float32\")\n",
        "        mask = cv2.imread(f\"{augmented_masks_dir}/{file_name}\", cv2.IMREAD_GRAYSCALE).astype(\"uint8\")\n",
        "        mask[mask == 255] = 1  # Normalize mask\n",
        "\n",
        "        # Resize\n",
        "        image = cv2.resize(image, (input_image_size, input_image_size))\n",
        "        mask = cv2.resize(mask, (input_image_size, input_image_size))\n",
        "\n",
        "        # Save compressed\n",
        "        np.savez_compressed(f\"{compressed_dir}/{file_name}.npz\", image=image, mask=mask)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to compress {file_name}: {e}\")\n"
      ],
      "metadata": {
        "id": "wM6w056Kh2cn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check augmented data\n",
        "print(\"Augmented images:\", os.listdir(augmented_images_dir)[:5])\n",
        "print(\"Augmented masks:\", os.listdir(augmented_masks_dir)[:5])\n",
        "\n",
        "# Check compressed data\n",
        "print(\"Compressed files:\", os.listdir(compressed_dir)[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKTe3XvqJFUc",
        "outputId": "d7f1bfba-1aa1-40ff-942c-6473cb646e36"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented images: ['00_556.png', '01_556.png', '02_556.png', '03_556.png', '04_556.png']\n",
            "Augmented masks: ['00_556.png', '01_556.png', '02_556.png', '03_556.png', '04_556.png']\n",
            "Compressed files: ['00_556.png.npz', '01_556.png.npz', '02_556.png.npz', '03_556.png.npz', '04_556.png.npz']\n"
          ]
        }
      ]
    }
  ]
}