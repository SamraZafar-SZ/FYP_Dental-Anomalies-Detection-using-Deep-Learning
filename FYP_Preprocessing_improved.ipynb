{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPvDOu_i94ip",
    "outputId": "20020ad5-7cd3-4d15-fb02-d20fb0f1fbfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.24)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.10.3)\n",
      "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.23)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.23->albumentations) (3.11.3)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Mount Google Drive to access your dataset\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install any missing dependencies\n",
    "!pip install albumentations opencv-python-headless numpy\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3E3Pn2v-MkI",
    "outputId": "216c097d-7d20-4573-b1a4-103cd65849d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "DecayDataSrc directory exists: True\n",
      "Contents of DecayDataSrc: ['Teeth_Dataset', 'Decay_Dataset', 'src']\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)\n",
    "\n",
    "# Path to the shortcut folder in your Google Drive\n",
    "BASE_DIR = \"/content/drive/My Drive/FYP_work/DecayDataSrc\"\n",
    "\n",
    "# Test if the shortcut folder is accessible\n",
    "import os\n",
    "\n",
    "print(\"DecayDataSrc directory exists:\", os.path.exists(BASE_DIR))\n",
    "print(\"Contents of DecayDataSrc:\", os.listdir(BASE_DIR) if os.path.exists(BASE_DIR) else \"Not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4iG3DvI4-eBy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def create_directory(path_segments):\n",
    "    \"\"\"Creates a directory if it does not exist.\"\"\"\n",
    "    path = os.path.join(*path_segments)\n",
    "    # Adding a check to see if path exists and if it's writable\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        except OSError as e:\n",
    "            if e.errno == 30:  # Read-only file system error\n",
    "                print(f\"Error: Cannot create directory '{path}'. File system is read-only.\")\n",
    "\n",
    "            else:\n",
    "                raise\n",
    "    elif os.path.isdir(path):\n",
    "        print(f\"Directory '{path}' already exists. Skipping creation.\")\n",
    "    else:\n",
    "        print(f\"Error: '{path}' exists but is not a directory.\")\n",
    "    return path\n",
    "\n",
    "\n",
    "def interpolate_image(image, target_size):\n",
    "    \"\"\"Interpolates an image to the target size.\"\"\"\n",
    "\n",
    "    return cv2.resize(image, target_size)\n",
    "\n",
    "BASE_DIR = \"/content/drive/My Drive/FYP_work/DecayDataSrc/Teeth_Dataset\"\n",
    "\n",
    "train_images_dir = f\"{BASE_DIR}/Train_Data/Images\"\n",
    "train_masks_dir = f\"{BASE_DIR}/Train_Data/Masks\"\n",
    "\n",
    "# Output directories\n",
    "augmented_images_dir = create_directory([BASE_DIR, \"augmented/Images1\"])\n",
    "augmented_masks_dir = create_directory([BASE_DIR, \"augmented/Masks1\"])\n",
    "compressed_dir = create_directory([BASE_DIR, \"compressed1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf-0rxaf_Lgd",
    "outputId": "6bfdc8c5-bfb2-4454-b13a-57f66aadba21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images directory exists: True\n",
      "Train masks directory exists: True\n",
      "Train Images: ['1.png', '10.png', '100.png', '101.png', '102.png']\n",
      "Train Masks: ['1.png', '10.png', '100.png', '101.png', '102.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check existence of directories\n",
    "print(\"Train images directory exists:\", os.path.exists(train_images_dir))\n",
    "print(\"Train masks directory exists:\", os.path.exists(train_masks_dir))\n",
    "\n",
    "# List files, sorted alphabetically\n",
    "if os.path.exists(train_images_dir):\n",
    "    train_images_files = sorted(os.listdir(train_images_dir)) # Sort the list of files\n",
    "    print(\"Train Images:\", train_images_files[:5])  # Show first 5 images\n",
    "\n",
    "if os.path.exists(train_masks_dir):\n",
    "    train_masks_files = sorted(os.listdir(train_masks_dir)) # Sort the list of files\n",
    "    print(\"Train Masks:\", train_masks_files[:5])  # Show first 5 masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVX6OxUJ_Ps4",
    "outputId": "235ff373-dfb9-4a4a-b48f-066fe6b52a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1.png <-> Mask: 1.png\n",
      "Image: 10.png <-> Mask: 10.png\n",
      "Image: 100.png <-> Mask: 100.png\n",
      "Image: 101.png <-> Mask: 101.png\n",
      "Image: 102.png <-> Mask: 102.png\n"
     ]
    }
   ],
   "source": [
    "#Check alignment of images and masks\n",
    "for i in range(5):\n",
    "    print(f\"Image: {train_images_files[i]} <-> Mask: {train_masks_files[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLNjmA3F_W8z"
   },
   "outputs": [],
   "source": [
    "input_image_size = 512\n",
    "target_shape = (input_image_size, input_image_size)\n",
    "# Augmentation transformations\n",
    "transform_crop = A.Compose([A.RandomCrop(width=input_image_size, height=input_image_size, p=1)])\n",
    "transform_rotate90 = A.Compose([A.RandomRotate90(p=1)])\n",
    "transform_flip = A.Compose([A.HorizontalFlip(p=1)])\n",
    "transform_brightness = A.Compose([A.RandomBrightnessContrast(p=1)])\n",
    "transform_all = A.Compose([\n",
    "    A.RandomCrop(width=input_image_size, height=input_image_size, p=1),\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.RandomBrightnessContrast(p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6ioZx1u_b48"
   },
   "source": [
    "Augmenting Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJu1mhWQ_Zta"
   },
   "outputs": [],
   "source": [
    "# Augment training data\n",
    "for file_name in train_images_files:\n",
    "    try:\n",
    "        # Load image and mask\n",
    "        image = cv2.imread(os.path.join(train_images_dir, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(os.path.join(train_masks_dir, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize image and mask to the target shape\n",
    "        image = cv2.resize(image, target_shape)\n",
    "        mask = cv2.resize(mask, target_shape)\n",
    "\n",
    "        # Normalize mask values\n",
    "        mask[mask == 255] = 1\n",
    "\n",
    "        # Save original data\n",
    "        cv2.imwrite(f\"{augmented_images_dir}/00_{file_name}\", image)\n",
    "\n",
    "\n",
    "        # Apply transformations and save\n",
    "        transformed = transform_crop(image=image, mask=mask)\n",
    "        cv2.imwrite(f\"{augmented_images_dir}/01_{file_name}\", transformed[\"image\"])\n",
    "\n",
    "\n",
    "        transformed = transform_rotate90(image=image, mask=mask)\n",
    "        cv2.imwrite(f\"{augmented_images_dir}/02_{file_name}\", transformed[\"image\"])\n",
    "\n",
    "\n",
    "        transformed = transform_flip(image=image, mask=mask)\n",
    "        cv2.imwrite(f\"{augmented_images_dir}/03_{file_name}\", transformed[\"image\"])\n",
    "\n",
    "\n",
    "        transformed = transform_all(image=image, mask=mask)\n",
    "        cv2.imwrite(f\"{augmented_images_dir}/04_{file_name}\", transformed[\"image\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTUQdFB5BHx0"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# Define transform_noise\n",
    "transform_noise = A.Compose([\n",
    "    A.RandomBrightnessContrast(p=1, always_apply=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRbyAuRJCDeY"
   },
   "outputs": [],
   "source": [
    "for file_name in train_images_files:\n",
    "    try:\n",
    "        # Load image and mask\n",
    "        image = cv2.imread(os.path.join(train_images_dir, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(os.path.join(train_masks_dir, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize image and mask to the target shape\n",
    "        image = cv2.resize(image, target_shape)\n",
    "        mask = cv2.resize(mask, target_shape)\n",
    "\n",
    "        if image is None or mask is None:\n",
    "            print(f\"Missing file: {file_name}\")\n",
    "            continue\n",
    "\n",
    "        # Normalize the mask: Convert white (255) to foreground (1), keep background as 0\n",
    "        mask[mask == 255] = 1\n",
    "\n",
    "        # Save the original mask\n",
    "        cv2.imwrite(f\"{augmented_masks_dir}/00_{file_name}\", (mask * 255).astype(\"uint8\"))\n",
    "\n",
    "        # Apply augmentations\n",
    "        transformed = transform_crop(image=image, mask=mask)\n",
    "        augmented_mask = transformed[\"mask\"]\n",
    "        cv2.imwrite(f\"{augmented_masks_dir}/01_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
    "\n",
    "        transformed = transform_rotate90(image=image, mask=mask)\n",
    "        augmented_mask = transformed[\"mask\"]\n",
    "        cv2.imwrite(f\"{augmented_masks_dir}/02_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
    "\n",
    "        transformed = transform_noise(image=image, mask=mask)\n",
    "        augmented_mask = transformed[\"mask\"]\n",
    "        cv2.imwrite(f\"{augmented_masks_dir}/03_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
    "\n",
    "        transformed = transform_all(image=image, mask=mask)\n",
    "        augmented_mask = transformed[\"mask\"]\n",
    "        cv2.imwrite(f\"{augmented_masks_dir}/04_{file_name}\", (augmented_mask * 255).astype(\"uint8\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbeL3OWzCNOT",
    "outputId": "afa81c2f-f630-4dfc-ccf3-92235921f619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Images (first 5):\n",
      "00_1.png\n",
      "00_10.png\n",
      "00_100.png\n",
      "00_101.png\n",
      "00_102.png\n",
      "\n",
      "Augmented Masks (first 5):\n",
      "00_1.png\n",
      "00_10.png\n",
      "00_100.png\n",
      "00_101.png\n",
      "00_102.png\n",
      "\n",
      "Alignment Check (first 5):\n",
      "Image: 00_1.png <-> Mask: 00_1.png\n",
      "Image: 00_10.png <-> Mask: 00_10.png\n",
      "Image: 00_100.png <-> Mask: 00_100.png\n",
      "Image: 00_101.png <-> Mask: 00_101.png\n",
      "Image: 00_102.png <-> Mask: 00_102.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Assuming augmented_images_dir and augmented_masks_dir are defined as in your code\n",
    "augmented_images_files = sorted(os.listdir(augmented_images_dir))\n",
    "augmented_masks_files = sorted(os.listdir(augmented_masks_dir))\n",
    "\n",
    "print(\"Augmented Images (first 5):\")\n",
    "for filename in augmented_images_files[:5]:\n",
    "    print(filename)\n",
    "\n",
    "print(\"\\nAugmented Masks (first 5):\")\n",
    "for filename in augmented_masks_files[:5]:\n",
    "    print(filename)\n",
    "\n",
    "# Check alignment (first 5)\n",
    "print(\"\\nAlignment Check (first 5):\")\n",
    "for i in range(5):\n",
    "    print(f\"Image: {augmented_images_files[i]} <-> Mask: {augmented_masks_files[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O1-yO7kCQh0"
   },
   "source": [
    "Compressing images and masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Is5W0YICOAZ",
    "outputId": "501af796-8d84-4033-ce30-8a7bfea49acb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed file 208: 01_77.png.npz\n",
      "Compressed file 201: 01_70.png.npz\n",
      "Compressed file 148: 01_22.png.npz\n",
      "Compressed file 426: 03_64.png.npz\n",
      "Compressed file 276: 02_33.png.npz\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Compressing images and their masks together\n",
    "compressed_dir = f\"{BASE_DIR}/compressed1\"\n",
    "os.makedirs(compressed_dir, exist_ok=True)\n",
    "\n",
    "augmented_images_files = sorted(os.listdir(augmented_images_dir))\n",
    "augmented_masks_files = sorted(os.listdir(augmented_masks_dir))\n",
    "\n",
    "#Check if number of images and masks are equal\n",
    "if len(augmented_images_files) != len(augmented_masks_files):\n",
    "    print(\"Error: Unequal number of images and masks!\")\n",
    "    #Handle error appropriately\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "for i in range(len(augmented_images_files)):\n",
    "    image_filename = augmented_images_files[i]\n",
    "    mask_filename = augmented_masks_files[i]\n",
    "\n",
    "    # Extract common prefix (e.g. \"00_\", \"01_\", etc.)\n",
    "    image_prefix = image_filename.split('_')[0]\n",
    "    mask_prefix = mask_filename.split('_')[0]\n",
    "\n",
    "    if image_prefix != mask_prefix:\n",
    "        print(f\"Mismatch detected! Image prefix: {image_prefix}, Mask prefix: {mask_prefix} at index: {i}\")\n",
    "        continue  # Skip this pair if there is a mismatch\n",
    "\n",
    "    try:\n",
    "        # Load augmented image and mask ENSURING MATCHING NAMES\n",
    "        image_path = os.path.join(augmented_images_dir, image_filename)\n",
    "        mask_path = os.path.join(augmented_masks_dir, mask_filename)\n",
    "\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE).astype(\"float32\")\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(\"uint8\")\n",
    "        mask[mask == 255] = 1 # Normalize mask\n",
    "\n",
    "        # Resize\n",
    "        image = cv2.resize(image, (input_image_size, input_image_size))\n",
    "        mask = cv2.resize(mask, (input_image_size, input_image_size))\n",
    "\n",
    "        #Save compressed with matching name\n",
    "        np.savez_compressed(\n",
    "            os.path.join(compressed_dir, f\"{image_filename}.npz\"),\n",
    "            **{\n",
    "                f\"image_{image_filename}\": image,\n",
    "                f\"mask_{mask_filename}\": mask\n",
    "            }\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compress {image_filename} with {mask_filename}: {e}\")\n",
    "\n",
    "\n",
    "# Print 5 random compressed files for verification\n",
    "random_indices = random.sample(range(len(os.listdir(compressed_dir))), 5)\n",
    "\n",
    "for index in random_indices:\n",
    "    compressed_file = os.listdir(compressed_dir)[index]\n",
    "    print(f\"Compressed file {index +1}: {compressed_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
